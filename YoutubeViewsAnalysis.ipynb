{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e818050-6bbe-4ffd-9189-849e009dc7df",
   "metadata": {},
   "source": [
    " ## Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b13689b7-ae1f-47ff-9319-252dd05e7f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\rrp28\\anaconda3\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\rrp28\\anaconda3\\lib\\site-packages (3.10.0)\n",
      "Requirement already satisfied: seaborn in c:\\users\\rrp28\\anaconda3\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: wordcloud in c:\\users\\rrp28\\anaconda3\\lib\\site-packages (1.9.4)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\rrp28\\anaconda3\\lib\\site-packages (from pandas) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\rrp28\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\rrp28\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\rrp28\\anaconda3\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\rrp28\\anaconda3\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\rrp28\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\rrp28\\anaconda3\\lib\\site-packages (from matplotlib) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\rrp28\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\rrp28\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\rrp28\\anaconda3\\lib\\site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\rrp28\\anaconda3\\lib\\site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\rrp28\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: vaderSentiment in c:\\users\\rrp28\\anaconda3\\lib\\site-packages (3.3.2)\n",
      "Requirement already satisfied: requests in c:\\users\\rrp28\\anaconda3\\lib\\site-packages (from vaderSentiment) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rrp28\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rrp28\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rrp28\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rrp28\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (2025.7.14)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas matplotlib seaborn wordcloud\n",
    "# For sentiment analysis, we'll use a library called vaderSentiment\n",
    "!pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac849a38-6644-4f36-98ec-dc917a4a795b",
   "metadata": {},
   "source": [
    "## Data Cleaning and Preprocessing 🧹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7cea078f-fad0-4aa0-8880-e4f136928754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- First 5 Rows of the Combined Dataset ---\n",
      "      video_id trending_date  \\\n",
      "0  2kyS6SvSYSE      17.14.11   \n",
      "1  1ZAPwfrtAFY      17.14.11   \n",
      "2  5qpjK5DgCt4      17.14.11   \n",
      "3  puqaWrEC7tY      17.14.11   \n",
      "4  d380meD0W0M      17.14.11   \n",
      "\n",
      "                                               title          channel_title  \\\n",
      "0                 WE WANT TO TALK ABOUT OUR MARRIAGE           CaseyNeistat   \n",
      "1  The Trump Presidency: Last Week Tonight with J...        LastWeekTonight   \n",
      "2  Racist Superman | Rudy Mancuso, King Bach & Le...           Rudy Mancuso   \n",
      "3                   Nickelback Lyrics: Real or Fake?  Good Mythical Morning   \n",
      "4                           I Dare You: GOING BALD!?               nigahiga   \n",
      "\n",
      "   category_id              publish_time  \\\n",
      "0           22  2017-11-13T17:13:01.000Z   \n",
      "1           24  2017-11-13T07:30:00.000Z   \n",
      "2           23  2017-11-12T19:05:24.000Z   \n",
      "3           24  2017-11-13T11:00:04.000Z   \n",
      "4           24  2017-11-12T18:01:41.000Z   \n",
      "\n",
      "                                                tags    views   likes  \\\n",
      "0                                    SHANtell martin   748374   57527   \n",
      "1  last week tonight trump presidency|\"last week ...  2418783   97185   \n",
      "2  racist superman|\"rudy\"|\"mancuso\"|\"king\"|\"bach\"...  3191434  146033   \n",
      "3  rhett and link|\"gmm\"|\"good mythical morning\"|\"...   343168   10172   \n",
      "4  ryan|\"higa\"|\"higatv\"|\"nigahiga\"|\"i dare you\"|\"...  2095731  132235   \n",
      "\n",
      "   dislikes  comment_count                                  thumbnail_link  \\\n",
      "0      2966          15954  https://i.ytimg.com/vi/2kyS6SvSYSE/default.jpg   \n",
      "1      6146          12703  https://i.ytimg.com/vi/1ZAPwfrtAFY/default.jpg   \n",
      "2      5339           8181  https://i.ytimg.com/vi/5qpjK5DgCt4/default.jpg   \n",
      "3       666           2146  https://i.ytimg.com/vi/puqaWrEC7tY/default.jpg   \n",
      "4      1989          17518  https://i.ytimg.com/vi/d380meD0W0M/default.jpg   \n",
      "\n",
      "   comments_disabled  ratings_disabled  video_error_or_removed  \\\n",
      "0              False             False                   False   \n",
      "1              False             False                   False   \n",
      "2              False             False                   False   \n",
      "3              False             False                   False   \n",
      "4              False             False                   False   \n",
      "\n",
      "                                         description region   category_name  \n",
      "0  SHANTELL'S CHANNEL - https://www.youtube.com/s...     US  People & Blogs  \n",
      "1  One year after the presidential election, John...     US   Entertainment  \n",
      "2  WATCH MY PREVIOUS VIDEO â¶ \\n\\nSUBSCRIBE âº ...     US          Comedy  \n",
      "3  Today we find out if Link is a Nickelback amat...     US   Entertainment  \n",
      "4  I know it's been a while since we did this sho...     US   Entertainment  \n",
      "\n",
      "\n",
      "--- Dataset Information ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 158098 entries, 0 to 158097\n",
      "Data columns (total 18 columns):\n",
      " #   Column                  Non-Null Count   Dtype \n",
      "---  ------                  --------------   ----- \n",
      " 0   video_id                158098 non-null  object\n",
      " 1   trending_date           158098 non-null  object\n",
      " 2   title                   158098 non-null  object\n",
      " 3   channel_title           158098 non-null  object\n",
      " 4   category_id             158098 non-null  int64 \n",
      " 5   publish_time            158098 non-null  object\n",
      " 6   tags                    158098 non-null  object\n",
      " 7   views                   158098 non-null  int64 \n",
      " 8   likes                   158098 non-null  int64 \n",
      " 9   dislikes                158098 non-null  int64 \n",
      " 10  comment_count           158098 non-null  int64 \n",
      " 11  thumbnail_link          158098 non-null  object\n",
      " 12  comments_disabled       158098 non-null  bool  \n",
      " 13  ratings_disabled        158098 non-null  bool  \n",
      " 14  video_error_or_removed  158098 non-null  bool  \n",
      " 15  description             155059 non-null  object\n",
      " 16  region                  158098 non-null  object\n",
      " 17  category_name           158098 non-null  object\n",
      "dtypes: bool(3), int64(5), object(10)\n",
      "memory usage: 18.5+ MB\n",
      "\n",
      "\n",
      "--- Missing Values ---\n",
      "video_id                     0\n",
      "trending_date                0\n",
      "title                        0\n",
      "channel_title                0\n",
      "category_id                  0\n",
      "publish_time                 0\n",
      "tags                         0\n",
      "views                        0\n",
      "likes                        0\n",
      "dislikes                     0\n",
      "comment_count                0\n",
      "thumbnail_link               0\n",
      "comments_disabled            0\n",
      "ratings_disabled             0\n",
      "video_error_or_removed       0\n",
      "description               3039\n",
      "region                       0\n",
      "category_name                0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# --- 1. Load the Datasets and Add a 'region' Column ---\n",
    "# The path you got from kagglehub might be a zip file.\n",
    "# First, ensure the files are extracted into a folder.\n",
    "# Let's assume the path is '.../youtube-new/' where the CSVs are located.\n",
    "# Replace 'path/to/your/files' with the actual path printed in your last step.\n",
    "\n",
    "data_path = r'C:\\Users\\rrp28\\YouTube Trending Video Analytics' # IMPORTANT: Change this to your actual path\n",
    "\n",
    "files_to_load = {\n",
    "    'US': 'USvideos.csv',\n",
    "    'GB': 'GBvideos.csv',\n",
    "    'IN': 'INvideos.csv',\n",
    "    'CA': 'CAvideos.csv'\n",
    "}\n",
    "\n",
    "all_dfs = []\n",
    "for region, filename in files_to_load.items():\n",
    "    # Construct the full file path\n",
    "    file_path = os.path.join(data_path, filename)\n",
    "    try:\n",
    "        # Load the CSV file\n",
    "        df = pd.read_csv(file_path, encoding='latin1') # 'latin1' encoding helps with special characters\n",
    "        # Add the region column\n",
    "        df['region'] = region\n",
    "        all_dfs.append(df)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Warning: {filename} not found at {file_path}. Skipping.\")\n",
    "\n",
    "# Concatenate all DataFrames into one\n",
    "videos_df = pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "\n",
    "# --- 2. Load the Category JSON and Map Category Names ---\n",
    "\n",
    "# Load the JSON file (we'll use the US one as it's generally comprehensive)\n",
    "json_path = os.path.join(data_path, 'US_category_id.json')\n",
    "category_df = pd.read_json(json_path)\n",
    "\n",
    "# Create a dictionary to map category_id to category name\n",
    "category_map = {}\n",
    "for item in category_df['items']:\n",
    "    category_map[int(item['id'])] = item['snippet']['title']\n",
    "\n",
    "# Map the category names to our main DataFrame\n",
    "videos_df['category_name'] = videos_df['category_id'].map(category_map)\n",
    "\n",
    "\n",
    "# --- 3. Initial Inspection ---\n",
    "\n",
    "print(\"--- First 5 Rows of the Combined Dataset ---\")\n",
    "print(videos_df.head())\n",
    "\n",
    "print(\"\\n\\n--- Dataset Information ---\")\n",
    "videos_df.info()\n",
    "\n",
    "print(\"\\n\\n--- Missing Values ---\")\n",
    "print(videos_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3536f35b-35bd-40fa-a434-0acfa39aa429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Data Types After Cleaning ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 158098 entries, 0 to 158097\n",
      "Data columns (total 18 columns):\n",
      " #   Column                  Non-Null Count   Dtype              \n",
      "---  ------                  --------------   -----              \n",
      " 0   video_id                158098 non-null  object             \n",
      " 1   trending_date           158098 non-null  datetime64[ns]     \n",
      " 2   title                   158098 non-null  object             \n",
      " 3   channel_title           158098 non-null  object             \n",
      " 4   category_id             158098 non-null  int64              \n",
      " 5   publish_time            158098 non-null  datetime64[ns, UTC]\n",
      " 6   tags                    158098 non-null  object             \n",
      " 7   views                   158098 non-null  int64              \n",
      " 8   likes                   158098 non-null  int64              \n",
      " 9   dislikes                158098 non-null  int64              \n",
      " 10  comment_count           158098 non-null  int64              \n",
      " 11  thumbnail_link          158098 non-null  object             \n",
      " 12  comments_disabled       158098 non-null  bool               \n",
      " 13  ratings_disabled        158098 non-null  bool               \n",
      " 14  video_error_or_removed  158098 non-null  bool               \n",
      " 15  description             158098 non-null  object             \n",
      " 16  region                  158098 non-null  object             \n",
      " 17  category_name           158098 non-null  object             \n",
      "dtypes: bool(3), datetime64[ns, UTC](1), datetime64[ns](1), int64(5), object(8)\n",
      "memory usage: 18.5+ MB\n",
      "\n",
      "\n",
      "--- Missing Values After Cleaning ---\n",
      "video_id                  0\n",
      "trending_date             0\n",
      "title                     0\n",
      "channel_title             0\n",
      "category_id               0\n",
      "publish_time              0\n",
      "tags                      0\n",
      "views                     0\n",
      "likes                     0\n",
      "dislikes                  0\n",
      "comment_count             0\n",
      "thumbnail_link            0\n",
      "comments_disabled         0\n",
      "ratings_disabled          0\n",
      "video_error_or_removed    0\n",
      "description               0\n",
      "region                    0\n",
      "category_name             0\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "--- Sample of Cleaned Date Columns ---\n",
      "  trending_date              publish_time\n",
      "0    2017-11-14 2017-11-13 17:13:01+00:00\n",
      "1    2017-11-14 2017-11-13 07:30:00+00:00\n",
      "2    2017-11-14 2017-11-12 19:05:24+00:00\n",
      "3    2017-11-14 2017-11-13 11:00:04+00:00\n",
      "4    2017-11-14 2017-11-12 18:01:41+00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rrp28\\AppData\\Local\\Temp\\ipykernel_13956\\2869788280.py:14: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  videos_df['description'].fillna('', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Fix Date and Time Columns ---\n",
    "\n",
    "# The 'trending_date' is in YY.DD.MM format. We specify this format for pandas to understand it correctly.\n",
    "videos_df['trending_date'] = pd.to_datetime(videos_df['trending_date'], format='%y.%d.%m')\n",
    "\n",
    "# The 'publish_time' is in ISO 8601 format, which pandas can often infer automatically.\n",
    "# We'll convert it and then extract just the date part for easier comparison later.\n",
    "videos_df['publish_time'] = pd.to_datetime(videos_df['publish_time'])\n",
    "\n",
    "\n",
    "# --- 2. Handle Missing Descriptions ---\n",
    "\n",
    "# We'll fill the NaN (Not a Number) values in the description with an empty string.\n",
    "videos_df['description'].fillna('', inplace=True)\n",
    "\n",
    "\n",
    "# --- 3. Final Check ---\n",
    "\n",
    "print(\"--- Data Types After Cleaning ---\")\n",
    "videos_df.info()\n",
    "\n",
    "print(\"\\n\\n--- Missing Values After Cleaning ---\")\n",
    "print(videos_df.isnull().sum())\n",
    "\n",
    "print(\"\\n\\n--- Sample of Cleaned Date Columns ---\")\n",
    "print(videos_df[['trending_date', 'publish_time']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8984f3-9b18-4992-b3b2-c78f1d5e50aa",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA) & SQL 📊"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99281ad0-f9f2-4aeb-a4ff-3b0e64814249",
   "metadata": {},
   "source": [
    "### Top 10 Trending Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7d0d5a2-83cf-4399-b239-79d65f59a37e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame has been successfully saved to the 'videos' table in youtube_trends.db\n",
      "\n",
      "\n",
      "--- Top 10 Trending Categories (All Regions) ---\n",
      "          category_name  number_of_videos\n",
      "0         Entertainment             49251\n",
      "1                 Music             27815\n",
      "2       News & Politics             13112\n",
      "3        People & Blogs             12865\n",
      "4                Comedy             12487\n",
      "5         Howto & Style              8926\n",
      "6      Film & Animation              8640\n",
      "7                Sports              7599\n",
      "8  Science & Technology              4626\n",
      "9             Education              4331\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "# --- 1. Create a database connection ---\n",
    "# This will create a file named 'youtube_trends.db' in your folder\n",
    "conn = sqlite3.connect('youtube_trends.db')\n",
    "\n",
    "# --- 2. Save our DataFrame to an SQL table ---\n",
    "# We'll name the table 'videos'. If it already exists, we'll replace it.\n",
    "videos_df.to_sql('videos', conn, if_exists='replace', index=False)\n",
    "\n",
    "print(\"DataFrame has been successfully saved to the 'videos' table in youtube_trends.db\")\n",
    "\n",
    "\n",
    "# --- 3. Write and Execute our First SQL Query ---\n",
    "# Let's find the top 10 categories with the most trending videos across all regions.\n",
    "query = \"\"\"\n",
    "SELECT\n",
    "    category_name,\n",
    "    COUNT(*) AS number_of_videos\n",
    "FROM\n",
    "    videos\n",
    "GROUP BY\n",
    "    category_name\n",
    "ORDER BY\n",
    "    number_of_videos DESC\n",
    "LIMIT 10;\n",
    "\"\"\"\n",
    "\n",
    "# Use pandas to run the query and get the result as a DataFrame\n",
    "top_categories = pd.read_sql_query(query, conn)\n",
    "\n",
    "\n",
    "# --- 4. Close the connection and view results ---\n",
    "conn.close()\n",
    "\n",
    "print(\"\\n\\n--- Top 10 Trending Categories (All Regions) ---\")\n",
    "print(top_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632dcfcb-3216-4627-a8fe-4e84f8316077",
   "metadata": {},
   "source": [
    "### Which Categories Get the Most Views?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d06b444-483b-444d-acac-63d20870ad74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--- Top 10 Categories by Average Views ---\n",
      "           category_name  average_views  average_likes  average_comments\n",
      "0                  Music      8435177.0       214942.0           17557.0\n",
      "1                 Movies      3007296.0        41616.0            2315.0\n",
      "2       Film & Animation      2596421.0        53294.0            5712.0\n",
      "3  Nonprofits & Activism      1975326.0       152543.0           48212.0\n",
      "4          Entertainment      1628033.0        41790.0            5847.0\n",
      "5                 Sports      1595446.0        34995.0            4162.0\n",
      "6   Science & Technology      1519962.0        38611.0            7110.0\n",
      "7                 Gaming      1345976.0        49215.0            7770.0\n",
      "8                 Comedy      1255354.0        58451.0            5823.0\n",
      "9         People & Blogs      1186460.0        35025.0            4895.0\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# --- 1. Connect to our database ---\n",
    "conn = sqlite3.connect('youtube_trends.db')\n",
    "\n",
    "# --- 2. Write and Execute the New SQL Query ---\n",
    "# Query to rank categories by their average view count.\n",
    "# We'll also get average likes and comments to be more thorough.\n",
    "query = \"\"\"\n",
    "SELECT\n",
    "    category_name,\n",
    "    ROUND(AVG(views)) AS average_views,\n",
    "    ROUND(AVG(likes)) AS average_likes,\n",
    "    ROUND(AVG(comment_count)) AS average_comments\n",
    "FROM\n",
    "    videos\n",
    "GROUP BY\n",
    "    category_name\n",
    "ORDER BY\n",
    "    average_views DESC\n",
    "LIMIT 10;\n",
    "\"\"\"\n",
    "\n",
    "# Run the query\n",
    "performance_by_category = pd.read_sql_query(query, conn)\n",
    "\n",
    "# --- 3. Close the connection and view results ---\n",
    "conn.close()\n",
    "\n",
    "print(\"\\n\\n--- Top 10 Categories by Average Views ---\")\n",
    "print(performance_by_category)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c34cd17-821e-4482-91e3-978aba0e2683",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "619a15c0-2089-4a2b-bdcc-b8d0ac618b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Sentiment Analysis of Video Titles ---\n",
      "sentiment\n",
      "Neutral     91769\n",
      "Positive    37493\n",
      "Negative    28836\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- Sentiment Distribution (%) ---\n",
      "sentiment\n",
      "Neutral     58.045643\n",
      "Positive    23.715038\n",
      "Negative    18.239320\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Make sure you have it installed: pip install vaderSentiment\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import pandas as pd # Ensure pandas is imported\n",
    "\n",
    "# We need to work with our original DataFrame again\n",
    "# If you don't have videos_df in memory, you might need to reload it and clean it again.\n",
    "# For now, we'll assume 'videos_df' is still available from our earlier steps.\n",
    "\n",
    "# 1. Initialize the VADER sentiment analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# 2. Define a function to get the sentiment\n",
    "def get_sentiment(title):\n",
    "    # The 'compound' score is a single metric for the overall sentiment\n",
    "    # Ranges from -1 (most negative) to +1 (most positive)\n",
    "    compound_score = analyzer.polarity_scores(title)['compound']\n",
    "    \n",
    "    if compound_score >= 0.05:\n",
    "        return 'Positive'\n",
    "    elif compound_score <= -0.05:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "\n",
    "# 3. Apply the function to our 'title' column\n",
    "# This will take a moment as it processes over 150,000 titles.\n",
    "videos_df['sentiment'] = videos_df['title'].apply(get_sentiment)\n",
    "\n",
    "# 4. Analyze the results\n",
    "sentiment_counts = videos_df['sentiment'].value_counts()\n",
    "\n",
    "print(\"--- Sentiment Analysis of Video Titles ---\")\n",
    "print(sentiment_counts)\n",
    "\n",
    "# You can also see the percentage\n",
    "print(\"\\n--- Sentiment Distribution (%) ---\")\n",
    "print(videos_df['sentiment'].value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de4c1b6-ad53-4ad8-996e-78845991ac2b",
   "metadata": {},
   "source": [
    "## Time-Series Analysis (Trend Duration) ⏳"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09115606-0be8-48de-b5a9-4de5dbc00aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Trend Duration Analysis ---\n",
      "The average trending duration for a video is: 3.50 days\n",
      "\n",
      "\n",
      "--- Average Trending Duration by Category (in Days) ---\n",
      "category_name\n",
      "Music                   23.21\n",
      "Movies                  18.36\n",
      "Film & Animation        16.86\n",
      "Pets & Animals          15.86\n",
      "Gaming                  12.20\n",
      "Entertainment           11.75\n",
      "Science & Technology    11.53\n",
      "Howto & Style           11.41\n",
      "Comedy                  10.53\n",
      "People & Blogs          10.37\n",
      "Name: trending_duration_days, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# We'll continue working with our 'videos_df' DataFrame\n",
    "\n",
    "# 1. Calculate trending duration for each video\n",
    "# We group by video_id and use transform('count') to create a new column\n",
    "# that shows how many times each video_id appeared.\n",
    "videos_df['trending_duration_days'] = videos_df.groupby('video_id')['video_id'].transform('count')\n",
    "\n",
    "# 2. Calculate the overall average trending duration\n",
    "# We'll look at the duration for unique videos only to get an accurate average.\n",
    "# We first drop duplicates to avoid counting the same video multiple times.\n",
    "average_duration = videos_df[['video_id', 'trending_duration_days']].drop_duplicates()['trending_duration_days'].mean()\n",
    "\n",
    "print(f\"--- Trend Duration Analysis ---\")\n",
    "print(f\"The average trending duration for a video is: {average_duration:.2f} days\")\n",
    "\n",
    "# 3. Analyze the average duration by category\n",
    "duration_by_category = videos_df.groupby('category_name')['trending_duration_days'].mean().round(2).sort_values(ascending=False)\n",
    "\n",
    "print(\"\\n\\n--- Average Trending Duration by Category (in Days) ---\")\n",
    "print(duration_by_category.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be1d29d-d089-43d6-a044-3f87cb506c31",
   "metadata": {},
   "source": [
    "## Final Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6bc76d34-57d2-4dcc-8461-650c39189f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dataset 'youtube_analysis_final.csv' has been saved!\n"
     ]
    }
   ],
   "source": [
    "# Save the final DataFrame to a CSV\n",
    "videos_df.to_csv('youtube_analysis_final.csv', index=False)\n",
    "\n",
    "print(\"Final dataset 'youtube_analysis_final.csv' has been saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10170e21-ce1d-4ace-a249-0f56ee004439",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
